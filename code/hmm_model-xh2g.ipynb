{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as Math\n",
    "import matplotlib\n",
    "matplotlib.use(\"Pdf\")\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def date2time(date):\n",
    "    time_array=date.split()\n",
    "    time_sub=time_array[1].split('.')\n",
    "    array=time_sub[0].split(':')\n",
    "    time=int(array[0])*3600+int(array[1])*60+int(array[2]) \n",
    "    return time\n",
    "\n",
    "def compute_time_interval(start, end):\n",
    "   \n",
    "    start_time = date2time(start)\n",
    "    end_time = date2time(end)\n",
    "    \n",
    "    # 相减得到秒数\n",
    "    seconds = end_time - start_time\n",
    "#     print(start, end, seconds)\n",
    "    \n",
    "    return seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = 6378137\n",
    "rj = 6356725\n",
    "from math import atan, cos, asin, sqrt, pow, pi, sin\n",
    "def rad(d):\n",
    "    return d * math.pi / 180.0\n",
    "\n",
    "def azimuth(pt_a, pt_b):\n",
    "    lon_a, lat_a = pt_a\n",
    "    lon_b, lat_b = pt_b\n",
    "    rlon_a, rlat_a = rad(lon_a), rad(lat_a)\n",
    "    rlon_b, rlat_b = rad(lon_b), rad(lat_b)\n",
    "    ec=rj+(rc-rj)*(90.-lat_a)/90.\n",
    "    ed=ec*cos(rlat_a)\n",
    "\n",
    "    dx = (rlon_b - rlon_a) * ec\n",
    "    dy = (rlat_b - rlat_a) * ed\n",
    "    if dy == 0:\n",
    "        angle = 90. \n",
    "    else:\n",
    "        angle = atan(abs(dx / dy)) * 180.0 / pi\n",
    "    dlon = lon_b - lon_a\n",
    "    dlat = lat_b - lat_a\n",
    "    if dlon > 0 and dlat <= 0:\n",
    "        angle = (90. - angle) + 90\n",
    "    elif dlon <= 0 and dlat < 0:\n",
    "        angle = angle + 180 \n",
    "    elif dlon < 0 and dlat >= 0:\n",
    "        angle = (90. - angle) + 270 \n",
    "    return angle\n",
    "\n",
    "def distance(true_pt, pred_pt):\n",
    "    lat1 = float(true_pt[1])\n",
    "    lng1 = float(true_pt[0])\n",
    "    lat2 = float(pred_pt[1])\n",
    "    lng2 = float(pred_pt[0])\n",
    "    radLat1 = rad(lat1)\n",
    "    radLat2 = rad(lat2)\n",
    "    a = radLat1 - radLat2\n",
    "    b = rad(lng1) - rad(lng2)\n",
    "    s = 2 * Math.asin(Math.sqrt(Math.pow(Math.sin(a/2),2) +\n",
    "    Math.cos(radLat1)*Math.cos(radLat2)*Math.pow(Math.sin(b/2),2)))\n",
    "    s = s * 6378.137\n",
    "    s = round(s * 10000) / 10\n",
    "    return s\n",
    "\n",
    "def sq(x):\n",
    "    return x*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name_new = [\n",
    "    #'Num_connected',\n",
    "    'TrajID',\n",
    "    'RNCID_1',\n",
    "    'CellID_1',\n",
    "    'EcNo_1',\n",
    "    'RSCP_1',\n",
    "    'RNCID_2',\n",
    "    'CellID_2',\n",
    "    'EcNo_2',\n",
    "    'RSCP_2',\n",
    "    'RNCID_3',\n",
    "    'CellID_3',\n",
    "    'EcNo_3',\n",
    "    'RSCP_3',\n",
    "    'RNCID_4',\n",
    "    'CellID_4',\n",
    "    'EcNo_4',\n",
    "    'RSCP_4',\n",
    "    'RNCID_5',\n",
    "    'CellID_5',\n",
    "    'EcNo_5',\n",
    "    'RSCP_5',\n",
    "    'RNCID_6',\n",
    "    'CellID_6',\n",
    "    'EcNo_6',\n",
    "    'RSCP_6',\n",
    "    #'RSSI_6',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name_rf = [\n",
    "    'RNCID_1',\n",
    "    'CellID_1',\n",
    "    'EcNo_1',\n",
    "    'RSCP_1',\n",
    "    'RNCID_2',\n",
    "    'CellID_2',\n",
    "    'EcNo_2',\n",
    "    'RSCP_2',\n",
    "    'RNCID_3',\n",
    "    'CellID_3',\n",
    "    'EcNo_3',\n",
    "    'RSCP_3',\n",
    "    'RNCID_4',\n",
    "    'CellID_4',\n",
    "    'EcNo_4',\n",
    "    'RSCP_4',\n",
    "    'RNCID_5',\n",
    "    'CellID_5',\n",
    "    'EcNo_5',\n",
    "    'RSCP_5',\n",
    "    'RNCID_6',\n",
    "    'CellID_6',\n",
    "    'EcNo_6',\n",
    "    'RSCP_6',\n",
    "    'Lon','Lat','Lon2','Lat2','Lon3','Lat3','Lon4','Lat4','Lon5','Lat5','Lon6','Lat6'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_2g_engpara():\n",
    "    eng_para = pd.read_csv('Unicom/Eng_para/2G工参20160505.CSV', encoding='gbk')\n",
    "    eng_para = eng_para[['LAC', 'CI', u'经度', u'纬度']]\n",
    "    eng_para = eng_para[eng_para.LAC.notnull() & eng_para[u'经度'].notnull()]\n",
    "    eng_para = eng_para.drop_duplicates()\n",
    "    eng_para.rename(columns={u'经度': 'Lon', u'纬度': 'Lat'}, inplace=True)        \n",
    "    eng_para['BSID'] = range(len(eng_para))\n",
    "    eng_para['BSID'] = eng_para['BSID'].map(lambda x: x + 1)\n",
    "    \n",
    "    return eng_para\n",
    "\n",
    "def make_rf_dataset(data, eng_para):\n",
    "    for i in range(1, 7):\n",
    "        data = data.merge(eng_para, left_on=['RNCID_%d' % i, 'CellID_%d' % i], right_on=['LAC','CI'], how='left', suffixes=('', '%d' % i))\n",
    "        temp=data['CellID_%d'% i].tolist()\n",
    "        new=list()\n",
    "        for item in temp:\n",
    "            if math.isnan(item):\n",
    "                new.append(0)\n",
    "            elif int(item)<=0:\n",
    "                new.append(0)\n",
    "            else:\n",
    "                new.append(item)\n",
    "        data['CellID_%d' % i]=new\n",
    "    data = data.fillna(-999.)\n",
    "    #print data.columns\n",
    "    \n",
    "    feature = data[col_name_new+['MRTime','BSID','BSID2','BSID3','BSID4','BSID5','BSID6','Longitude', 'Latitude',\n",
    "                                 'Lon','Lat','Lon2','Lat2','Lon3','Lat3','Lon4','Lat4','Lon5','Lat5','Lon6','Lat6']]\n",
    "   \n",
    "    \n",
    "    subset=[u'Longitude', u'Latitude', \n",
    "       u'RNCID_1', u'CellID_1',u'EcNo_1',u'RSCP_1',\n",
    "       u'RNCID_2', u'CellID_2',u'EcNo_2',u'RSCP_2',\n",
    "       u'RNCID_3', u'CellID_3',u'EcNo_3',u'RSCP_3',\n",
    "       u'RNCID_4', u'CellID_4',u'EcNo_4',u'RSCP_4',\n",
    "       u'RNCID_5', u'CellID_5',u'EcNo_5',u'RSCP_5',\n",
    "       u'RNCID_6', u'CellID_6',u'EcNo_6',u'RSCP_6',\n",
    "       ]\n",
    "    feature=feature.drop_duplicates(subset=subset) \n",
    "    label = feature[['Longitude', 'Latitude']]\n",
    "    #feature= feature.drop(['Longitude', 'Latitude'],axis=1)\n",
    "    \n",
    "    return feature, label\n",
    "\n",
    "#eng_para = merge_2g_engpara()\n",
    "eng_para =merge_2g_engpara()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_model_label(error):\n",
    "    conf_l=list()\n",
    "   \n",
    "    for t in error:\n",
    "        if t<=50:\n",
    "            conf_l.append(1)\n",
    "        else:\n",
    "            conf_l.append(0)\n",
    "    \n",
    "    return conf_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0427bd528c55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdf3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdf3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TrajID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdf3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TrajID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TrajID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TrajID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdf4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unicom/GSM Mr/Result_步测数据导出2G-2.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   2173\u001b[0m             \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2174\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2175\u001b[0;31m             \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2177\u001b[0m         return self._constructor(new_values,\n",
      "\u001b[0;32mpandas/src/inference.pyx\u001b[0m in \u001b[0;36mpandas.lib.map_infer (pandas/lib.c:66116)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-0427bd528c55>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdf3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdf3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TrajID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdf3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TrajID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TrajID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TrajID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdf4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unicom/GSM Mr/Result_步测数据导出2G-2.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mstat_func\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m   5623\u001b[0m                                       skipna=skipna)\n\u001b[1;32m   5624\u001b[0m         return self._reduce(f, name, axis=axis, skipna=skipna,\n\u001b[0;32m-> 5625\u001b[0;31m                             numeric_only=numeric_only)\n\u001b[0m\u001b[1;32m   5626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5627\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mset_function_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstat_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m_reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   2315\u001b[0m                 raise NotImplementedError('Series.{0} does not implement '\n\u001b[1;32m   2316\u001b[0m                                           'numeric_only.'.format(name))\n\u001b[0;32m-> 2317\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3064\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3065\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moldstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseterr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3066\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_Unspecified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moldcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseterrcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36mseterr\u001b[0;34m(all, divide, over, under, invalid)\u001b[0m\n\u001b[1;32m   2757\u001b[0m     maskvalue = ((_errdict[divide] << SHIFT_DIVIDEBYZERO) +\n\u001b[1;32m   2758\u001b[0m                  \u001b[0;34m(\u001b[0m\u001b[0m_errdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mover\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<<\u001b[0m \u001b[0mSHIFT_OVERFLOW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2759\u001b[0;31m                  \u001b[0;34m(\u001b[0m\u001b[0m_errdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<<\u001b[0m \u001b[0mSHIFT_UNDERFLOW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2760\u001b[0m                  (_errdict[invalid] << SHIFT_INVALID))\n\u001b[1;32m   2761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('Unicom/GSM Mr/Result_路测数据导出2G正向-1.csv', sep='\\t')\n",
    "df1 = df1.drop_duplicates()\n",
    "df1['TrajID'] = range(len(df1))\n",
    "df1['TrajID'] = df1['TrajID'].map(lambda x: x//60)\n",
    "\n",
    "df2 = pd.read_csv('Unicom/GSM Mr/Result_路测数据导出2G反向-1.csv', sep='\\t')\n",
    "df2 = df2.drop_duplicates()\n",
    "df2['TrajID'] = range(len(df2))\n",
    "df2['TrajID'] = df2['TrajID'].map(lambda x: x//60+df1['TrajID'].max()+1)\n",
    "\n",
    "df3 = pd.read_csv('Unicom/GSM Mr/Result_步测数据导出2G-1.csv', sep='\\t')\n",
    "df3 = df3.drop_duplicates()\n",
    "df3['TrajID'] = range(len(df3))\n",
    "df3['TrajID'] = df3['TrajID'].map(lambda x: x//60+df2['TrajID'].max()+1)\n",
    "\n",
    "df4 = pd.read_csv('Unicom/GSM Mr/Result_步测数据导出2G-2.csv', sep='\\t')\n",
    "df4 = df4.drop_duplicates()\n",
    "df4['TrajID'] = range(len(df4))\n",
    "df4['TrajID'] = df4['TrajID'].map(lambda x: x//60+df3['TrajID'].max()+1)\n",
    "\n",
    "data_2g = pd.concat([df1, df2, df3, df4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_2g.to_csv('xh2g.csv', index=False)\n",
    "data_2g = pd.read_csv('xh2g.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1、邻接基站实验\n",
    "bs_num = []\n",
    "for idx,row in data_2g.iterrows():\n",
    "    for i in range(1,8):\n",
    "        if row['RNCID_%d'%i]==0 or math.isnan(row['RNCID_%d'%i]) or row['CellID_%d'%i]==-1 or math.isnan(row['CellID_%d'%i]):\n",
    "            bs_num.append(i-1)\n",
    "            break\n",
    "        if i == 7:\n",
    "            bs_num.append(i)        \n",
    "data_2g['bs_num'] = bs_num\n",
    "retain_num = int(sys.argv[1])\n",
    "# retain_num = 1\n",
    "for idx,row in data_2g.iterrows():\n",
    "    if row['bs_num']-1 <= retain_num:\n",
    "        continue\n",
    "    for i in range(retain_num+2, row['bs_num']+1):\n",
    "        data_2g.loc[idx, 'RNCID_%d'%i] = np.nan\n",
    "        data_2g.loc[idx, 'CellID_%d'%i] = np.nan\n",
    "        data_2g.loc[idx, 'AsuLevel_%d'%i] = np.nan\n",
    "        data_2g.loc[idx, 'SignalLevel_%d'%i] = np.nan\n",
    "        data_2g.loc[idx, 'Dbm_%d'%i] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2、基站密度实验\n",
    "bs = []\n",
    "for i in range(1, 7):\n",
    "    bs += data_2g[['RNCID_%d'% i, 'CellID_%d'% i]].values.tolist()\n",
    "bs = [tuple(t) for t in bs]\n",
    "temp = []\n",
    "[temp.append(i) for i in bs if not i in temp]\n",
    "bs = temp\n",
    "ratio = float(sys.argv[1])\n",
    "# ratio = 0.5\n",
    "drop_bs = random.sample(bs, int(len(bs) * ratio))\n",
    "for idx, row in data_2g.iterrows():\n",
    "    for i in range(1, 7):\n",
    "        if (row['RNCID_%d'% i], row['CellID_%d'% i]) in drop_bs:\n",
    "            data_2g.loc[idx, 'RNCID_%d'% i] = -999\n",
    "            data_2g.loc[idx, 'CellID_%d'% i] = -999\n",
    "            data_2g.loc[idx, 'EcNo_%d'% i] = -999\n",
    "            data_2g.loc[idx, 'RSCP_%d'% i] = -999   \n",
    "data_2g = data_2g.drop(data_2g[data_2g['RNCID_1']==-999].index)              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3、运动模式实验\n",
    "mode = sys.argv[1]\n",
    "if mode == '0':\n",
    "    df1 = pd.read_csv('Unicom/GSM Mr/Result_步测数据导出2G-1.csv', sep='\\t')\n",
    "    df1 = df1.drop_duplicates()\n",
    "    df1['TrajID'] = range(len(df1))\n",
    "    df1['TrajID'] = df1['TrajID'].map(lambda x: x//60)\n",
    "    df2 = pd.read_csv('Unicom/GSM Mr/Result_步测数据导出2G-2.csv', sep='\\t')\n",
    "    df2 = df2.drop_duplicates()\n",
    "    df2['TrajID'] = range(len(df2))\n",
    "    df2['TrajID'] = df2['TrajID'].map(lambda x: x//60+df1['TrajID'].max()+1)\n",
    "else:\n",
    "    df1 = pd.read_csv('Unicom/GSM Mr/Result_路测数据导出2G正向-1.csv', sep='\\t')\n",
    "    df1 = df1.drop_duplicates()\n",
    "    df1['TrajID'] = range(len(df1))\n",
    "    df1['TrajID'] = df1['TrajID'].map(lambda x: x//60)\n",
    "    df2 = pd.read_csv('Unicom/GSM Mr/Result_路测数据导出2G反向-1.csv', sep='\\t')\n",
    "    df2 = df2.drop_duplicates()\n",
    "    df2['TrajID'] = range(len(df2))\n",
    "    df2['TrajID'] = df2['TrajID'].map(lambda x: x//60+df1['TrajID'].max()+1)\n",
    "\n",
    "data = pd.concat([df1, df2])\n",
    "data_2g = data.drop_duplicates(col_name_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "train, label = make_rf_dataset(data_2g, eng_para)\n",
    "from sklearn.cross_validation import train_test_split\n",
    "tr_feature_r, te_feature_r, tr_label_, te_label_ = train_test_split(train, label, test_size=0.4,random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71364"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_pre(data):\n",
    "    data=data.iloc[:,1:]\n",
    "    label=data[['Longitude','Latitude']]\n",
    "    data=data.drop(['Longitude', 'Latitude'],axis=1)\n",
    "    \n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_tr_feature, con_te_feature, con_tr_p, con_te_p = train_test_split(te_feature_r, te_label_, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_feature_r = tr_feature_r.sort_values(by='MRTime')\n",
    "con_tr_feature = con_tr_feature.sort_values(by='MRTime')\n",
    "con_te_feature = con_te_feature.sort_values(by='MRTime')\n",
    "tr_label_ = tr_feature_r[['Longitude', 'Latitude']]\n",
    "con_tr_p = con_tr_feature[['Longitude', 'Latitude']]\n",
    "con_te_p = con_te_feature[['Longitude', 'Latitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#con_tr_feature.to_csv(\"2g/conf_tr_jd2g.csv\")\n",
    "#con_te_feature.to_csv(\"2g/conf_te_jd2g.csv\")\n",
    "#tr_feature_r.to_csv(\"2g/total_conf_tr_jd2g.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import grid\n",
    "\n",
    "rg = grid.RoadGrid(np.vstack((tr_label_.values, te_label_.values)),50)\n",
    "tr_label_g = rg.transform(tr_label_.values, False) #grid索引\n",
    "#rint tr_label_\n",
    "con_tr_j = rg.transform(con_tr_p.values, False)\n",
    "con_te_j = rg.transform(con_te_p.values, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(con_tr_p.iloc[:,0].values, con_tr_p.iloc[:,1].values, 'ro')\n",
    "plt.plot(con_te_p.iloc[:,0].values, con_te_p.iloc[:,1].values, 'bo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"est=RandomForestClassifier( n_jobs=-1,\\n    n_estimators =50,\\n    max_features='sqrt'\\n).fit(tr_feature_r[col_name_rf].values, tr_label_g)\\n\\npred_tr=est.predict(tr_feature_r[col_name_rf].values)\\ntr_pred = np.array([rg.grid_center[idx] for idx in pred_tr])\\nerror_tr = [distance(pt1, pt2) for pt1, pt2 in zip(tr_pred, tr_label_.values)]\\n\\npred_con_tr=est.predict(con_tr_feature[col_name_rf].values)\\npred_con_te=est.predict(con_te_feature[col_name_rf].values)\\ntr_con_pred = np.array([rg.grid_center[idx] for idx in pred_con_tr])\\nte_con_pred = np.array([rg.grid_center[idx] for idx in pred_con_te])\\nerror_con_tr = [distance(pt1, pt2) for pt1, pt2 in zip(tr_con_pred, con_tr_p.values)]\\nerror_con_te = [distance(pt1, pt2) for pt1, pt2 in zip(te_con_pred, con_te_p.values)]\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''est=RandomForestClassifier( n_jobs=-1,\n",
    "    n_estimators =50,\n",
    "    max_features='sqrt'\n",
    ").fit(tr_feature_r[col_name_rf].values, tr_label_g)\n",
    "\n",
    "pred_tr=est.predict(tr_feature_r[col_name_rf].values)\n",
    "tr_pred = np.array([rg.grid_center[idx] for idx in pred_tr])\n",
    "error_tr = [distance(pt1, pt2) for pt1, pt2 in zip(tr_pred, tr_label_.values)]\n",
    "\n",
    "pred_con_tr=est.predict(con_tr_feature[col_name_rf].values)\n",
    "pred_con_te=est.predict(con_te_feature[col_name_rf].values)\n",
    "tr_con_pred = np.array([rg.grid_center[idx] for idx in pred_con_tr])\n",
    "te_con_pred = np.array([rg.grid_center[idx] for idx in pred_con_te])\n",
    "error_con_tr = [distance(pt1, pt2) for pt1, pt2 in zip(tr_con_pred, con_tr_p.values)]\n",
    "error_con_te = [distance(pt1, pt2) for pt1, pt2 in zip(te_con_pred, con_te_p.values)]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "est=RandomForestRegressor( n_jobs=-1,\n",
    "    n_estimators =200,\n",
    "    max_features='sqrt'\n",
    ").fit(tr_feature_r[col_name_rf].values, tr_label_)\n",
    "\n",
    "pred_tr=est.predict(tr_feature_r[col_name_rf].values)\n",
    "tr_pred = pred_tr\n",
    "error_tr = [distance(pt1, pt2) for pt1, pt2 in zip(tr_pred, tr_label_.values)]\n",
    "\n",
    "pred_con_tr=est.predict(con_tr_feature[col_name_rf].values)\n",
    "pred_con_te=est.predict(con_te_feature[col_name_rf].values)\n",
    "tr_con_pred = pred_con_tr\n",
    "te_con_pred = pred_con_te\n",
    "error_con_tr = [distance(pt1, pt2) for pt1, pt2 in zip(tr_con_pred, con_tr_p.values)]\n",
    "error_con_te = [distance(pt1, pt2) for pt1, pt2 in zip(te_con_pred, con_te_p.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineer(feature, pred, timestamp, ):\n",
    "    add_feature = []\n",
    "    timestamp_new=np.array(timestamp)\n",
    "    timest_array=[]\n",
    "    for item in timestamp_new:\n",
    "        time_array=item.split()\n",
    "        time_sub=time_array[1].split('.')\n",
    "        array=time_sub[0].split(':')\n",
    "        time=int(array[0])*3600+int(array[1])*60+int(array[2]) \n",
    "        timest_array.append(time)\n",
    "    for i in range(0, len(pred)):\n",
    "        if i == 0:\n",
    "            last_pt = pred[i]\n",
    "            last_time = timest_array[i]\n",
    "        else:\n",
    "            last_pt = pred[i-1]\n",
    "            last_time = timest_array[i-1]\n",
    "        if i == len(pred)-1:\n",
    "            next_pt = pred[i]\n",
    "            next_time = timest_array[i]\n",
    "        else:\n",
    "            next_pt = pred[i+1]\n",
    "            next_time = timest_array[i+1]\n",
    "        sub_add_feature = []\n",
    "        sub_add_feature.append(distance(last_pt, pred[i]))\n",
    "        sub_add_feature.append(distance(next_pt, pred[i]))\n",
    "        sub_add_feature.append(azimuth(last_pt, pred[i]))\n",
    "        sub_add_feature.append(azimuth(pred[i], next_pt))\n",
    "        sub_add_feature.append(timest_array[i]-last_time if timest_array[i]-last_time > 0 else 0)\n",
    "        sub_add_feature.append(next_time-timest_array[i] if next_time-timest_array[i] > 0 else 0)\n",
    "        sub_add_feature.append(sub_add_feature[0] / sub_add_feature[4] if sub_add_feature[4] > 0 else 0)\n",
    "        sub_add_feature.append(sub_add_feature[1] / sub_add_feature[5] if sub_add_feature[5] > 0 else 0)\n",
    "        sub_add_feature.append(last_pt[0])\n",
    "        sub_add_feature.append(last_pt[1])\n",
    "        sub_add_feature.append(next_pt[0])\n",
    "        sub_add_feature.append(next_pt[1])\n",
    "        sub_add_feature.append(pred[i][0])\n",
    "        sub_add_feature.append(pred[i][1])\n",
    "        #sub_add_feature.append(grid[i])\n",
    "        add_feature.append(sub_add_feature)\n",
    "    add_feature = np.asarray(add_feature)\n",
    "    feature = np.hstack((feature, add_feature))\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_tr = feature_engineer(tr_feature_r[col_name_rf], tr_pred, tr_feature_r['MRTime'])\n",
    "feature_con_tr = feature_engineer(con_tr_feature[col_name_rf], tr_con_pred, con_tr_feature['MRTime'])\n",
    "feature_con_te = feature_engineer(con_te_feature[col_name_rf], te_con_pred, con_te_feature['MRTime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: o",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-697a1b206f46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtr_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_center\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_con_tr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mte_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_center\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_con_te\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0merror_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpt2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpt2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcon_tr_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0merror_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpt2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpt2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mte_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcon_te_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-1c3eb2902612>\u001b[0m in \u001b[0;36mdistance\u001b[0;34m(true_pt, pred_pt)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mlat1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_pt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mlng1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_pt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mlat2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_pt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mlng2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_pt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mradLat1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlat1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: o"
     ]
    }
   ],
   "source": [
    "est1=RandomForestClassifier( n_jobs=-1,\n",
    "    n_estimators =200,\n",
    "    max_features='sqrt'\n",
    ").fit(feature_tr, tr_label_g)\n",
    "pred_con_tr=est1.predict(feature_con_tr)\n",
    "pred_con_te=est1.predict(feature_con_te)\n",
    "tr_pred = np.array([rg.grid_center[idx] for idx in pred_con_tr])\n",
    "te_pred = np.array([rg.grid_center[idx] for idx in pred_con_te])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_tr = [distance(pt1, pt2) for pt1, pt2 in zip(tr_pred, con_tr_p.values)]\n",
    "error_te = [distance(pt1, pt2) for pt1, pt2 in zip(te_pred, con_te_p.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19.300000000000001, 44.050275856029423, 119.9)\n"
     ]
    }
   ],
   "source": [
    "error_te = sorted(error_te)\n",
    "print(np.median(error_te), np.mean(error_te), error_te[int(len(error_te) * 0.9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_feature_r['Longitude'] = tr_label_.iloc[:, 0].values\n",
    "tr_feature_r['Latitude'] = tr_label_.iloc[:, 1].values\n",
    "tr_feature_r['gid'] = tr_label_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_label_tr = conf_model_label(error_tr)\n",
    "conf_label_te = conf_model_label(error_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_tr_feature[\"conf\"]= conf_label_tr\n",
    "con_te_feature[\"conf\"]= conf_label_te\n",
    "con_tr_feature[\"error\"]= error_tr\n",
    "con_te_feature[\"error\"]= error_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_tr_feature['Longitude'] = con_tr_p.iloc[:,0]\n",
    "con_tr_feature['Latitude'] = con_tr_p.iloc[:,1]\n",
    "con_te_feature['Longitude'] = con_te_p.iloc[:,0]\n",
    "con_te_feature['Latitude'] = con_te_p.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_tr_feature['p_gid'] = pred_con_tr\n",
    "con_tr_feature['gid'] = con_tr_j\n",
    "con_te_feature['p_gid'] = pred_con_te\n",
    "con_te_feature['gid'] = con_te_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rss_level(dbm):\n",
    "    if dbm>-50:\n",
    "        return 1\n",
    "    elif dbm >-60:\n",
    "        return 2\n",
    "    elif dbm >-70:\n",
    "        return 3\n",
    "    elif dbm>-80:\n",
    "        return 4\n",
    "    elif dbm>-90:\n",
    "        return 5\n",
    "    elif dbm>-100:\n",
    "        return 6\n",
    "    elif dbm>-110:\n",
    "        return 7\n",
    "    else:\n",
    "        return 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 7):\n",
    "    con_tr_feature['Dbm_%d' % i] = con_tr_feature['RSCP_%d' % i] - con_tr_feature['EcNo_%d' % i]\n",
    "    con_te_feature['Dbm_%d' % i] = con_te_feature['RSCP_%d' % i] - con_te_feature['EcNo_%d' % i]\n",
    "    con_tr_feature['rss_level_%d' % i] = con_tr_feature['Dbm_%d' % i].map(lambda x: rss_level(x))  \n",
    "    con_te_feature['rss_level_%d' % i] = con_te_feature['Dbm_%d' % i].map(lambda x: rss_level(x))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ob = con_tr_feature[['BSID','rss_level_1','BSID2','rss_level_2',\n",
    "               'BSID3','rss_level_3','BSID4','rss_level_4',\n",
    "               'BSID5','rss_level_5','BSID6','rss_level_6',]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ob_bs = con_tr_feature[['BSID','BSID2','BSID3','BSID4','BSID5','BSID6',]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ob_rss = con_tr_feature[['rss_level_1','rss_level_2','rss_level_3',\n",
    "                               'rss_level_4','rss_level_5','rss_level_6',]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ob_te = con_te_feature[['BSID','rss_level_1','BSID2','rss_level_2',\n",
    "               'BSID3','rss_level_3','BSID4','rss_level_4',\n",
    "               'BSID5','rss_level_5','BSID6','rss_level_6',]].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive Emission Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_sim(list1, list2):\n",
    "    #print list1, list2\n",
    "    union_set = len(set(list1)|set(list2))#并集长度\n",
    "    intersection_set = len(set(list1)&set(list2))#交集长度\n",
    "\n",
    "    Jaccard = float(intersection_set/union_set) #Jaccar\n",
    "    return Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_emission_pro(jd_list, match, bs_list, ss_list, can_list, total_c, conf):\n",
    "    pro_list = []\n",
    "    weight_list = []\n",
    "    if match.shape[0]>0:\n",
    "        weight_list.append(math.log(1+match.shape[0])*1)\n",
    "        match_ss= match[(match['rss_level_1']== int(ss_list[0])) & (match['rss_level_2']==int(ss_list[1])) & (match['rss_level_3']==ss_list[2])\n",
    "             & (match['rss_level_4']==ss_list[3]) & (match['rss_level_5']==ss_list[4]) & (match['rss_level_6']==ss_list[5])]\n",
    "        if match_ss.shape[0]>0:\n",
    "            pro_list.append(float(match_ss[match_ss['conf']==conf].shape[0])/float(total_c))\n",
    "        else:\n",
    "            pro_list.append(float(match[match['conf']==conf].shape[0])/float(total_c))\n",
    "        \n",
    "        \n",
    "    for can_temp, jd in zip(can_list, jd_list):\n",
    "        match_c = con_tr_feature[(con_tr_feature['BSID']==int(can_temp[0])) & (con_tr_feature['BSID2']==int(can_temp[1]))\n",
    "                      &(con_tr_feature['BSID3']==int(can_temp[2])) & (con_tr_feature['BSID4']==int(can_temp[3]))\n",
    "                      &(con_tr_feature['BSID5']==int(can_temp[4])) & (con_tr_feature['BSID6']==int(can_temp[5]))]\n",
    "        count = match_c.shape[0]\n",
    "        weight_list.append(math.log(1+count)*jd)\n",
    "        \n",
    "        match_ss_c= match_c[(match_c['rss_level_1']== ss_list[0]) & (match_c['rss_level_2']== ss_list[1]) \n",
    "                            & (match_c['rss_level_3']==ss_list[2])& (match_c['rss_level_4']==ss_list[3]) \n",
    "                            & (match_c['rss_level_5']==ss_list[4]) & (match_c['rss_level_6']==ss_list[5])]\n",
    "        if match_ss_c.shape[0]>0:\n",
    "            pro_list.append(float(match_ss_c[match_ss_c['conf']==conf].shape[0])/float(total_c))\n",
    "        else:\n",
    "            pro_list.append(float(match_c[match_c['conf']==conf].shape[0])/float(total_c))\n",
    "\n",
    "\n",
    "    weight_sum = np.sum(weight_list)\n",
    "    ad_em_po = 0\n",
    "    \n",
    "    for x, y in zip(pro_list, weight_list):\n",
    "        ad_em_po += x * (y / weight_sum)\n",
    "    \n",
    "    return ad_em_po"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros_list = []\n",
    "i =0\n",
    "j=0\n",
    "zero_num = con_tr_feature[con_tr_feature['conf']==0].shape[0]\n",
    "for idx, row in total_ob_te.iterrows():\n",
    "    bs_list =row[['BSID','BSID2','BSID3','BSID4','BSID5','BSID6']].values\n",
    "    ss_list = row[['rss_level_1','rss_level_2','rss_level_3','rss_level_4','rss_level_5','rss_level_6',]].values\n",
    "    #print bs_list[0]\n",
    "    match = con_tr_feature[(con_tr_feature['BSID']==int(bs_list[0])) & (con_tr_feature['BSID2']==int(bs_list[1]))\n",
    "                          &(con_tr_feature['BSID3']==int(bs_list[2])) & (con_tr_feature['BSID4']==int(bs_list[3]))\n",
    "                          &(con_tr_feature['BSID5']==int(bs_list[4])) & (con_tr_feature['BSID6']==int(bs_list[5]))]\n",
    "    if match.shape[0]<5: \n",
    "        can_bs_row = [] \n",
    "        can_j = [] \n",
    "        jaccd_max = [] \n",
    "        idx_list = []\n",
    "        for idxx, roww in total_ob_bs.iterrows():\n",
    "            can_bs_list = roww.values\n",
    "            jd = jaccard_sim(bs_list, can_bs_list)\n",
    "            jaccd_max.append(jd)\n",
    "            idx_list.append(idxx)\n",
    "            if jd>0.5:\n",
    "                can_bs_row.append(can_bs_list)\n",
    "                can_j.append(jd)\n",
    "                \n",
    "        if len(can_bs_row)==0: \n",
    "            can_idx = jaccd_max.index(np.max(jaccd_max))\n",
    "            can_temp = total_ob_bs.iloc[can_idx,:].values\n",
    "            can_bs_row.append(total_ob_bs.iloc[can_idx,:].values)\n",
    "            match_c = con_tr_feature[(con_tr_feature['BSID']==int(can_temp[0])) & (con_tr_feature['BSID2']==int(can_temp[1]))\n",
    "                          &(con_tr_feature['BSID3']==int(can_temp[2])) & (con_tr_feature['BSID4']==int(can_temp[3]))\n",
    "                          &(con_tr_feature['BSID5']==int(can_temp[4])) & (con_tr_feature['BSID6']==int(can_temp[5]))]\n",
    "            \n",
    "            match_ss_c= match_c[(match_c['rss_level_1']== ss_list[0]) & (match_c['rss_level_2']== ss_list[1]) \n",
    "                            & (match_c['rss_level_3']==ss_list[2])& (match_c['rss_level_4']==ss_list[3]) \n",
    "                            & (match_c['rss_level_5']==ss_list[4]) & (match_c['rss_level_6']==ss_list[5])]\n",
    "            if match_ss_c.shape[0]>0:\n",
    "                zeros_list.append(float(match_ss_c[match_ss_c['conf']==0].shape[0])/float(zero_num))\n",
    "            else:\n",
    "                zeros_list.append(float(match_c[match_c['conf']==0].shape[0])/float(zero_num))\n",
    "        \n",
    "            j+=1 \n",
    "        else:\n",
    "            zeros_list.append(adaptive_emission_pro(can_j, match, bs_list, ss_list, can_bs_row, zero_num, 0))\n",
    "        #print i, len(can_bs_row)\n",
    "        i+=1\n",
    "    else:\n",
    "        j+=1\n",
    "        match_ss= match[(match['rss_level_1']== int(ss_list[0])) & (match['rss_level_2']==int(ss_list[1])) & (match['rss_level_3']==ss_list[2])\n",
    "             & (match['rss_level_4']==ss_list[3]) & (match['rss_level_5']==ss_list[4]) & (match['rss_level_6']==ss_list[5])]\n",
    "        if match_ss.shape[0]>0:\n",
    "            zeros_list.append(float(match_ss[match_ss['conf']==0].shape[0])/float(zero_num))\n",
    "        else:\n",
    "            zeros_list.append(float(match[match['conf']==0].shape[0])/float(zero_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ob_te['conf_ad_em_pro_0'] = zeros_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_list = []\n",
    "one_num = con_tr_feature[con_tr_feature['conf']==1].shape[0]\n",
    "for idx, row in total_ob_te.iterrows():\n",
    "    bs_list =row[['BSID','BSID2','BSID3','BSID4','BSID5','BSID6']].values\n",
    "    ss_list = row[['rss_level_1','rss_level_2','rss_level_3','rss_level_4','rss_level_5','rss_level_6',]].values\n",
    "    #print bs_list[0]\n",
    "    match = con_tr_feature[(con_tr_feature['BSID']==int(bs_list[0])) & (con_tr_feature['BSID2']==int(bs_list[1]))\n",
    "                          &(con_tr_feature['BSID3']==int(bs_list[2])) & (con_tr_feature['BSID4']==int(bs_list[3]))\n",
    "                          &(con_tr_feature['BSID5']==int(bs_list[4])) & (con_tr_feature['BSID6']==int(bs_list[5]))]\n",
    "    if match.shape[0]<5:\n",
    "        can_bs_row = []\n",
    "        can_j = []\n",
    "        jaccd_max = []\n",
    "        idx_list = []\n",
    "        for idxx, roww in total_ob_bs.iterrows():\n",
    "            can_bs_list = roww.values\n",
    "            jd = jaccard_sim(bs_list, can_bs_list)\n",
    "            jaccd_max.append(jd)\n",
    "            idx_list.append(idxx)\n",
    "            if jd>0.5:\n",
    "                can_bs_row.append(can_bs_list)\n",
    "                can_j.append(jd)\n",
    "                \n",
    "        if len(can_bs_row)==0:\n",
    "            can_idx = jaccd_max.index(np.max(jaccd_max))\n",
    "            can_temp = total_ob_bs.iloc[can_idx,:].values\n",
    "            can_bs_row.append(total_ob_bs.iloc[can_idx,:].values)\n",
    "            match_c = con_tr_feature[(con_tr_feature['BSID']==int(can_temp[0])) & (con_tr_feature['BSID2']==int(can_temp[1]))\n",
    "                          &(con_tr_feature['BSID3']==int(can_temp[2])) & (con_tr_feature['BSID4']==int(can_temp[3]))\n",
    "                          &(con_tr_feature['BSID5']==int(can_temp[4])) & (con_tr_feature['BSID6']==int(can_temp[5]))]\n",
    "            \n",
    "            match_ss_c= match_c[(match_c['rss_level_1']== ss_list[0]) & (match_c['rss_level_2']== ss_list[1]) \n",
    "                            & (match_c['rss_level_3']==ss_list[2])& (match_c['rss_level_4']==ss_list[3]) \n",
    "                            & (match_c['rss_level_5']==ss_list[4]) & (match_c['rss_level_6']==ss_list[5])]\n",
    "            if match_ss_c.shape[0]>0:\n",
    "                one_list.append(float(match_ss_c[match_ss_c['conf']==1].shape[0])/float(one_num))\n",
    "            else:\n",
    "                one_list.append(float(match_c[match_c['conf']==1].shape[0])/float(one_num))\n",
    "        \n",
    "        else:\n",
    "            one_list.append(adaptive_emission_pro(can_j, match, bs_list, ss_list, can_bs_row, one_num, 1))\n",
    "        \n",
    "    else:\n",
    "       \n",
    "        match_ss= match[(match['rss_level_1']== int(ss_list[0])) & (match['rss_level_2']==int(ss_list[1])) & (match['rss_level_3']==ss_list[2])\n",
    "             & (match['rss_level_4']==ss_list[3]) & (match['rss_level_5']==ss_list[4]) & (match['rss_level_6']==ss_list[5])]\n",
    "        if match_ss.shape[0]>0:\n",
    "            one_list.append(float(match_ss[match_ss['conf']==1].shape[0])/float(one_num))\n",
    "        else:\n",
    "            one_list.append(float(match[match['conf']==1].shape[0])/float(one_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ob_te['conf_ad_em_pro_1'] = one_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_te_feature['gid'] = con_te_j\n",
    "con_te_feature['p_gid'] = pred_con_te\n",
    "con_tr_feature['gid'] = con_tr_j\n",
    "con_tr_feature['p_gid'] = pred_con_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajs_tr = con_tr_feature.groupby(['TrajID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive State Transition Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_list = []\n",
    "st_mat = np.zeros((14,2,2)) #0-0 0-1 1-0, 1-1\n",
    "for trajid, traj in trajs_tr:\n",
    "    traj = traj.sort_values(by=['MRTime'],ascending=True)\n",
    "    t_time = traj['MRTime'].values\n",
    "    conf = traj['conf'].values\n",
    "    for i in range(traj.shape[0]-1):\n",
    "        time_list.append(compute_time_interval(t_time[i], t_time[i + 1]))\n",
    "        idx = int(compute_time_interval(t_time[i], t_time[i + 1])/5)\n",
    "        if idx >12:\n",
    "            idx = 13\n",
    "        if conf[i]==0 and conf[i+1]==0:\n",
    "            st_mat[idx, 0, 0] +=1\n",
    "        if conf[i] ==0 and conf[i+1] ==1:\n",
    "            st_mat[idx, 0, 1] +=1\n",
    "        if conf[i]==1 and conf[i+1]==0:\n",
    "            st_mat[idx, 1, 0] +=1\n",
    "        if conf[i] ==1 and conf[i+1] ==1:\n",
    "            st_mat[idx, 1, 1] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(time_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajs_te = con_te_feature.groupby(['TrajID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_t_idx = [] \n",
    "pred_list = [] \n",
    "p_g_list = []\n",
    "t_g_list = []\n",
    "t_gr_list = []\n",
    "for trajid, traj in trajs_te:\n",
    "    traj = traj.sort_values(by=['MRTime'],ascending=True)\n",
    "    t_time = traj['MRTime'].values\n",
    "    conf = traj['conf'].values\n",
    "    idx_list = [] \n",
    "    for i in range(traj.shape[0]-1): \n",
    "        time_list.append(compute_time_interval(t_time[i], t_time[i + 1]))\n",
    "        idx = int(compute_time_interval(t_time[i], t_time[i + 1])/5)\n",
    "        if idx >12:\n",
    "            idx = 13\n",
    "        idx_list.append(idx)\n",
    "    pred_list.append(traj[['BSID','rss_level_1','BSID2','rss_level_2',\n",
    "               'BSID3','rss_level_3','BSID4','rss_level_4',\n",
    "               'BSID5','rss_level_5','BSID6','rss_level_6',]].values)\n",
    "        \n",
    "    pred_list_t_idx.append(idx_list)\n",
    "    p_g_list.append(traj['p_gid'].values)\n",
    "    t_gr_list.append(traj['gid'].values)\n",
    "    t_g_list.append(traj[['Longitude','Latitude']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_prob = [float(con_tr_feature[con_tr_feature['conf']==0].shape[0])/con_tr_feature.shape[0],\n",
    "             float(con_tr_feature[con_tr_feature['conf']==1].shape[0])/con_tr_feature.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hmm_viterbi(st_mat, init_prob, emit_prob, obs_seq, t_list):\n",
    "    Nstate = 2\n",
    "    Nobs = int(emit_prob.shape[0])\n",
    "    T = len(obs_seq)\n",
    "    \n",
    "    partial_prob = np.zeros((Nstate,T))\n",
    "\n",
    "    path = np.zeros((Nstate,T))\n",
    "\n",
    "    for i in range(Nstate):\n",
    "        partial_prob[i,0] = init_prob[i] * emit_prob[obs_seq[0], i]\n",
    "        path[i,0] = i\n",
    "\n",
    "\n",
    "    for t in range(1,T,1):\n",
    "        newpath = np.zeros((Nstate,T))\n",
    "        for i in range(Nstate):\n",
    "            prob = -1.0\n",
    "            for j in range(Nstate):\n",
    "                nprob = partial_prob[j,t-1] * st_mat[t_list[t-1], j, i] * emit_prob[obs_seq[t], i]\n",
    "                if nprob > prob:\n",
    "                    prob = nprob\n",
    "                    partial_prob[i,t] = nprob\n",
    "                    newpath[i,0:t] = path[j,0:t]\n",
    "                    newpath[i,t] = i\n",
    "        path = newpath\n",
    "    \n",
    "    prob = -1.0\n",
    "    j = 0\n",
    "    for i in range(Nstate):\n",
    "        if(partial_prob[i,T-1] > prob):\n",
    "            prob = partial_prob[i,T-1]\n",
    "            j = i\n",
    "\n",
    "    return path[j,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_pro = total_ob_te\n",
    "em_pro = em_pro.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "emit_prob = em_pro[['conf_ad_em_pro_0', 'conf_ad_em_pro_1']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_g = rg.n_grid\n",
    "w = np.zeros((num_g, num_g))\n",
    "c = np.zeros((num_g))\n",
    "test = zip(pred_con_tr, con_tr_j, error_tr) \n",
    "tj_r = {}\n",
    "for ss in test:\n",
    "    c[ss[0]]+=1\n",
    "    if ss[0]!=ss[1] and ss[2]>50:\n",
    "         w[ss[0]][ss[1]] +=1\n",
    "    if ss[0] not in tj_r:\n",
    "        tj_r[ss[0]]=set()\n",
    "    tj_r[ss[0]].add((ss[1]))\n",
    "\n",
    "standard_point=[]\n",
    "\n",
    "for item in tj_r:\n",
    "    #print item\n",
    "    if (len(tj_r[item])==1) and (item in tj_r[item]): \n",
    "        \n",
    "        standard_point.append(item)\n",
    "    \n",
    "for idx in range(num_g):\n",
    "    if idx not in tj_r:\n",
    "        tj_r[idx]=set()\n",
    "        tj_r[idx].add((idx))\n",
    "\n",
    "g_list=rg.gridlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_obs = {} \n",
    "for idx, row in con_tr_feature.iterrows():\n",
    "    obs = row[['BSID','rss_level_1','BSID2','rss_level_2',\n",
    "               'BSID3','rss_level_3','BSID4','rss_level_4',\n",
    "               'BSID5','rss_level_5','BSID6','rss_level_6',]].values\n",
    "    gid = int(row['gid'])\n",
    "    match = em_pro[(em_pro['BSID']==obs[0]) & (em_pro['rss_level_1']==obs[1]) & \n",
    "                      (em_pro['BSID2']==obs[2]) & (em_pro['rss_level_2']==obs[3]) & \n",
    "                      (em_pro['BSID3']==obs[4]) & (em_pro['rss_level_3']==obs[5]) & \n",
    "                      (em_pro['BSID4']==obs[6]) & (em_pro['rss_level_4']==obs[7]) & \n",
    "                      (em_pro['BSID5']==obs[8]) & (em_pro['rss_level_5']==obs[9]) & \n",
    "                      (em_pro['BSID6']==obs[10]) & (em_pro['rss_level_6']==obs[11])]\n",
    "    if match.shape[0]>0:\n",
    "        obs_idx = (gid, int(match.index[0]))\n",
    "        if obs_idx not in g_obs:\n",
    "            g_obs[obs_idx]=1\n",
    "        else:\n",
    "            g_obs[obs_idx] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repair(te_pred, cof_list, o_list, idx):\n",
    "    i=0\n",
    "    te_pred_n=[]\n",
    "    while i < len(cof_list):\n",
    "        \n",
    "        if cof_list[i]==0:\n",
    "            pred_temp = te_pred[i]\n",
    "            if pred_temp in standard_point:\n",
    "                te_pred_n.append(te_pred[i])\n",
    "            else:\n",
    "                repair_r = list(w[te_pred[i], :])\n",
    "                max_idx = repair_r.index(np.max(repair_r))\n",
    "                if (max_idx, o_list[i]) in g_obs and np.max(repair_r)>30 :\n",
    "                    te_pred_n.append(int(max_idx))\n",
    "                else:\n",
    "                    te_pred_n.append(te_pred[i])\n",
    "           \n",
    "        else:\n",
    "            pred_temp = te_pred[i]\n",
    "            if pred_temp in standard_point:\n",
    "                te_pred_n.append(te_pred[i])\n",
    "            else:\n",
    "                if i< cof_list.shape[0]-1:\n",
    "                    div_x=math.fabs(g_list[te_pred[i]][0]-g_list[te_pred[i+1]][0])\n",
    "                    div_y=math.fabs(g_list[te_pred[i]][1]-g_list[te_pred[i+1]][1])\n",
    "                    if sq(div_x)+sq(div_y)>9:\n",
    "                        te_pred_n.append(t_gr_list[idx][i])\n",
    "                    else:\n",
    "                        te_pred_n.append(te_pred[i])\n",
    "                else:\n",
    "                    te_pred_n.append(te_pred[i])\n",
    "            \n",
    "        i+=1\n",
    "   \n",
    "    return te_pred_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "error_list = []\n",
    "error_new =[]\n",
    "i=0\n",
    "for row, time, raw, gt in zip (pred_list, pred_list_t_idx, p_g_list, t_g_list):\n",
    "    \n",
    "    o_seq = []\n",
    "    for obs in row:\n",
    "        #print obs\n",
    "        match = em_pro[(em_pro['BSID']==obs[0]) & (em_pro['rss_level_1']==obs[1]) & \n",
    "                      (em_pro['BSID2']==obs[2]) & (em_pro['rss_level_2']==obs[3]) & \n",
    "                      (em_pro['BSID3']==obs[4]) & (em_pro['rss_level_3']==obs[5]) & \n",
    "                      (em_pro['BSID4']==obs[6]) & (em_pro['rss_level_4']==obs[7]) & \n",
    "                      (em_pro['BSID5']==obs[8]) & (em_pro['rss_level_5']==obs[9]) & \n",
    "                      (em_pro['BSID6']==obs[10]) & (em_pro['rss_level_6']==obs[11])]\n",
    "        o_seq.append(match.index[0])\n",
    "    pred = raw\n",
    "    true = gt\n",
    "    cof_list = hmm_viterbi(st_mat, init_prob, emit_prob, o_seq, time) #st_mat: 状态集合\n",
    "    r_pred = repair(pred, cof_list, o_seq, i)\n",
    "    \n",
    "    #print len(row)\n",
    "    te_predp = np.array([rg.grid_center[idx] for idx in r_pred])\n",
    "    #tps = np.array([rg.grid_center[idx] for idx in true])\n",
    "   \n",
    "    error_tep = [distance(pt1, pt2) for pt1, pt2 in zip(te_predp, true)]\n",
    "    #print np.mean(error_trp), np.mean(error_tep)\n",
    "   \n",
    "    for t in error_tep:\n",
    "        #print t\n",
    "        error_new.append(t)\n",
    "    i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "err= sorted(error_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18.399999999999999, 38.109764427708207, 97.7)\n"
     ]
    }
   ],
   "source": [
    "print(np.median(error_new), np.mean(error_new), err[int(len(err) * 0.9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "py27",
   "language": "python",
   "name": "py27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
