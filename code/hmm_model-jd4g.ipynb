{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as Math\n",
    "import matplotlib\n",
    "matplotlib.use(\"Pdf\")\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def compute_time_interval(start, end):\n",
    "   \n",
    "    start = datetime.datetime.fromtimestamp(start / 1000.0)\n",
    "    end = datetime.datetime.fromtimestamp(end / 1000.0)\n",
    "    \n",
    "    # 相减得到秒数\n",
    "    seconds = (end- start).seconds\n",
    "    \n",
    "    return seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcMean(x,y):\n",
    "    sum_x = sum(x)\n",
    "    sum_y = sum(y)\n",
    "    n = len(x)\n",
    "    x_mean = float(sum_x+0.0)/n\n",
    "    y_mean = float(sum_y+0.0)/n\n",
    "    return x_mean,y_mean\n",
    "\n",
    "def calcPearson(x,y):\n",
    "    x_mean,y_mean = calcMean(x,y)\t#计算x,y向量平均值\n",
    "    n = len(x)\n",
    "    sumTop = 0.0\n",
    "    sumBottom = 0.0\n",
    "    x_pow = 0.0\n",
    "    y_pow = 0.0\n",
    "    for i in range(n):\n",
    "        sumTop += (x[i]-x_mean)*(y[i]-y_mean)\n",
    "    for i in range(n):\n",
    "        x_pow += math.pow(x[i]-x_mean,2)\n",
    "    for i in range(n):\n",
    "        y_pow += math.pow(y[i]-y_mean,2)\n",
    "    sumBottom = math.sqrt(x_pow*y_pow)\n",
    "    p = sumTop/sumBottom\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist\n",
    "def distribution(data,low=0,up=125,r=5,bins=25):\n",
    "    p_list=np.zeros((bins))\n",
    "    i=0\n",
    "    total=len(data)\n",
    "    #print total\n",
    "    while low + r <= up:\n",
    "        for t in data:\n",
    "            if t >= low and t < low + r:\n",
    "                p_list[i] += 1\n",
    "        low += r\n",
    "        i += 1\n",
    "    p_u_list=list()\n",
    "    #print p_list\n",
    "    if len(data)>0:\n",
    "        for t in p_list:\n",
    "            #print int(t)\n",
    "            p_u_list.append(float(t)/float(total))\n",
    "    else:\n",
    "        p_u_list=p_list.tolist()\n",
    "    return p_u_list\n",
    "    \n",
    "def p_norm_distance(x,y):\n",
    "    #print x,y\n",
    "    X = np.vstack([x,y])\n",
    "    d2 = pdist(X,'minkowski',p=3)\n",
    "    return d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = 6378137\n",
    "rj = 6356725\n",
    "from math import atan, cos, asin, sqrt, pow, pi, sin\n",
    "def rad(d):\n",
    "    return d * math.pi / 180.0\n",
    "\n",
    "def azimuth(pt_a, pt_b):\n",
    "    lon_a, lat_a = pt_a\n",
    "    lon_b, lat_b = pt_b\n",
    "    rlon_a, rlat_a = rad(lon_a), rad(lat_a)\n",
    "    rlon_b, rlat_b = rad(lon_b), rad(lat_b)\n",
    "    ec=rj+(rc-rj)*(90.-lat_a)/90.\n",
    "    ed=ec*cos(rlat_a)\n",
    "\n",
    "    dx = (rlon_b - rlon_a) * ec\n",
    "    dy = (rlat_b - rlat_a) * ed\n",
    "    if dy == 0:\n",
    "        angle = 90. \n",
    "    else:\n",
    "        angle = atan(abs(dx / dy)) * 180.0 / pi\n",
    "    dlon = lon_b - lon_a\n",
    "    dlat = lat_b - lat_a\n",
    "    if dlon > 0 and dlat <= 0:\n",
    "        angle = (90. - angle) + 90\n",
    "    elif dlon <= 0 and dlat < 0:\n",
    "        angle = angle + 180 \n",
    "    elif dlon < 0 and dlat >= 0:\n",
    "        angle = (90. - angle) + 270 \n",
    "    return angle\n",
    "\n",
    "def distance(true_pt, pred_pt):\n",
    "    lat1 = float(true_pt[1])\n",
    "    lng1 = float(true_pt[0])\n",
    "    lat2 = float(pred_pt[1])\n",
    "    lng2 = float(pred_pt[0])\n",
    "    radLat1 = rad(lat1)\n",
    "    radLat2 = rad(lat2)\n",
    "    a = radLat1 - radLat2\n",
    "    b = rad(lng1) - rad(lng2)\n",
    "    s = 2 * Math.asin(Math.sqrt(Math.pow(Math.sin(a/2),2) +\n",
    "    Math.cos(radLat1)*Math.cos(radLat2)*Math.pow(Math.sin(b/2),2)))\n",
    "    s = s * 6378.137\n",
    "    s = round(s * 10000) / 10\n",
    "    return s\n",
    "\n",
    "def sq(x):\n",
    "    return x*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name_new = [\n",
    "    #'Num_connected',\n",
    "    'TrajID',\n",
    "    'RNCID_1',\n",
    "    'CellID_1',\n",
    "    'AsuLevel_1',\n",
    "    'Dbm_1',\n",
    "    'SignalLevel_1',\n",
    "    'RNCID_2',\n",
    "    'CellID_2',\n",
    "    'AsuLevel_2',\n",
    "    'Dbm_2',\n",
    "    'SignalLevel_2',\n",
    "    'RNCID_3',\n",
    "    'CellID_3',\n",
    "    'AsuLevel_3',\n",
    "    'Dbm_3',\n",
    "    'SignalLevel_3',\n",
    "    'RNCID_4',\n",
    "    'CellID_4',\n",
    "    'AsuLevel_4',\n",
    "    'Dbm_4',\n",
    "    'SignalLevel_4',\n",
    "    'RNCID_5',\n",
    "    'CellID_5',\n",
    "    'AsuLevel_5',\n",
    "    'Dbm_5',\n",
    "    'SignalLevel_5',\n",
    "    'RNCID_6',\n",
    "    'CellID_6',\n",
    "    'AsuLevel_6',\n",
    "    'Dbm_6',\n",
    "    'SignalLevel_6',\n",
    "    'mode',\n",
    "    'Basic_psc_pci_2','Basic_psc_pci_3','Basic_psc_pci_4','Basic_psc_pci_5','Basic_psc_pci_6'\n",
    "    #'RSSI_6',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name_rf = [\n",
    "    'RNCID_1',\n",
    "    'CellID_1',\n",
    "    'Lon', 'Lat',\n",
    "    'AsuLevel_1',\n",
    "    'Dbm_1',\n",
    "    'SignalLevel_1',\n",
    "    'AsuLevel_2',\n",
    "    'Dbm_2',\n",
    "    'SignalLevel_2',\n",
    "    'AsuLevel_3',\n",
    "    'Dbm_3',\n",
    "    'SignalLevel_3',\n",
    "    'AsuLevel_4',\n",
    "    'Dbm_4',\n",
    "    'SignalLevel_4',\n",
    "    'AsuLevel_5',\n",
    "    'Dbm_5',\n",
    "    'SignalLevel_5',\n",
    "    'AsuLevel_6',\n",
    "    'Dbm_6',\n",
    "    'SignalLevel_6',\n",
    "    'Basic_psc_pci_2','Basic_psc_pci_3','Basic_psc_pci_4','Basic_psc_pci_5','Basic_psc_pci_6'\n",
    "    #'RSSI_6',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_2g_engpara():\n",
    "    eng_para = pd.read_csv('4g/jiading_4g_new_gongcan.csv', encoding='gbk')\n",
    "    eng_para = eng_para[['RNCID', 'CellID', 'Lon','Lat', 'BSID',]]\n",
    "    #eng_para = eng_para[eng_para.LAC.notnull() & eng_para[u'经度'].notnull()]\n",
    "    eng_para = eng_para.drop_duplicates()\n",
    "    #eng_para.rename(columns={u'经度': 'lon', u'纬度': 'lat'}, inplace=True)\n",
    "    return eng_para\n",
    "\n",
    "def make_rf_dataset(data, eng_para):\n",
    "    for i in range(1, 7):\n",
    "        data = data.merge(eng_para, left_on=['RNCID_%d' % i, 'CellID_%d' % i], right_on=['RNCID','CellID'], how='left', suffixes=('', '%d' % i))\n",
    "        temp=data['CellID_%d'% i].tolist()\n",
    "        new=list()\n",
    "        for item in temp:\n",
    "            if math.isnan(item):\n",
    "                new.append(0)\n",
    "            elif int(item)<=0:\n",
    "                new.append(0)\n",
    "            else:\n",
    "                new.append(item)\n",
    "        data['CellID_%d' % i]=new\n",
    "    data = data.fillna(-999.)\n",
    "    #print data.columns\n",
    "    \n",
    "    feature = data[col_name_new+['MRTime','Lon','Lat','BSID','BSID2','BSID3','BSID4','BSID5','BSID6','Longitude', 'Latitude']]\n",
    "   \n",
    "    \n",
    "    subset=[u'Longitude', u'Latitude', \n",
    "       u'RNCID_1', u'CellID_1',u'Dbm_1',\n",
    "       u'RNCID_2', u'CellID_2',u'Dbm_2',\n",
    "       u'RNCID_3', u'CellID_3',u'Dbm_3',\n",
    "       u'RNCID_4', u'CellID_4',u'Dbm_4',\n",
    "       u'RNCID_5', u'CellID_5',u'Dbm_5',\n",
    "       u'RNCID_6', u'CellID_6',u'Dbm_6',\n",
    "       ]\n",
    "    #feature=feature.drop_duplicates(subset=subset) \n",
    "    label = feature[['Longitude', 'Latitude']]\n",
    "    feature= feature.drop(['Longitude', 'Latitude'],axis=1)\n",
    "    \n",
    "    return feature, label\n",
    "\n",
    "#eng_para = merge_2g_engpara()\n",
    "eng_para =merge_2g_engpara()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_model_label(error):\n",
    "    conf_l=list()\n",
    "    \n",
    "    for t in error:\n",
    "        if t<=50:\n",
    "            conf_l.append(1)\n",
    "        else:\n",
    "            conf_l.append(0)\n",
    "    \n",
    "    return conf_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2g=pd.read_csv(\"4g/jiading_4g_mode.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1、邻接基站实验\n",
    "bs_num = []\n",
    "for idx,row in data_2g.iterrows():\n",
    "    for i in range(1,8):\n",
    "        if row['RNCID_%d'%i]==0 or math.isnan(row['RNCID_%d'%i]) or row['CellID_%d'%i]==-1 or math.isnan(row['CellID_%d'%i]):\n",
    "            bs_num.append(i-1)\n",
    "            break\n",
    "        if i == 7:\n",
    "            bs_num.append(i)        \n",
    "data_2g['bs_num'] = bs_num\n",
    "retain_num = int(sys.argv[1])\n",
    "# retain_num = 1\n",
    "for idx,row in data_2g.iterrows():\n",
    "    if row['bs_num']-1 <= retain_num:\n",
    "        continue\n",
    "    for i in range(retain_num+2, row['bs_num']+1):\n",
    "        data_2g.loc[idx, 'RNCID_%d'%i] = np.nan\n",
    "        data_2g.loc[idx, 'CellID_%d'%i] = np.nan\n",
    "        data_2g.loc[idx, 'AsuLevel_%d'%i] = np.nan\n",
    "        data_2g.loc[idx, 'SignalLevel_%d'%i] = np.nan\n",
    "        data_2g.loc[idx, 'Dbm_%d'%i] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2、基站密度实验\n",
    "bs = []\n",
    "for i in range(1, 8):\n",
    "    bs += data_2g[['RNCID_%d'% i, 'CellID_%d'% i]].values.tolist()\n",
    "bs = [tuple(t) for t in bs]\n",
    "temp = []\n",
    "[temp.append(i) for i in bs if not i in temp]\n",
    "bs = temp\n",
    "ratio = float(sys.argv[1])\n",
    "drop_bs = random.sample(bs, int(len(bs) * ratio))\n",
    "for idx, row in data_2g.iterrows():\n",
    "    for i in range(1, 7):\n",
    "        if (row['RNCID_%d'% i], row['CellID_%d'% i]) in drop_bs:\n",
    "            data_2g.loc[idx, 'RNCID_%d'% i] = -999\n",
    "            data_2g.loc[idx, 'CellID_%d'% i] = -999\n",
    "            data_2g.loc[idx, 'Dbm_%d'% i] = -999\n",
    "data_2g = data_2g.drop(data_2g[data_2g['RNCID_1']==-999].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3、运动模式实验\n",
    "mode = int(sys.argv[1])\n",
    "data_2g = data_2g[data_2g['mode'] == mode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'TrajID', u'IMEI', u'IMSI', u'MRTime', u'Longitude', u'Latitude',\n",
      "       u'Altitude', u'Accuracy', u'Speed', u'Dbm',\n",
      "       ...\n",
      "       u'CellID_7', u'Arfcn_7', u'Basic_psc_pci_7', u'Lon_7', u'Lat_7',\n",
      "       u'AsuLevel_7', u'SignalLevel_7', u'Dbm_7', u'Type_7', u'mode'],\n",
      "      dtype='object', length=108)\n"
     ]
    }
   ],
   "source": [
    "train, label = make_rf_dataset(data_2g, eng_para)\n",
    "from sklearn.cross_validation import train_test_split\n",
    "tr_feature_r, te_feature_r, tr_label_, te_label_ = train_test_split(train, label, test_size=0.4,random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "19044\n",
      "36504\n",
      "51944\n",
      "64660\n"
     ]
    }
   ],
   "source": [
    "#n_bs_df = pd.DataFrame()\n",
    "n_bs_list = []\n",
    "for i in range(2, 7):\n",
    "    data = data_2g[data_2g['Basic_psc_pci_%d' % i]>0]\n",
    "    n_bs = data[['RNCID_1', 'CellID_1', 'Basic_psc_pci_%d' % i]].values\n",
    "    print len(n_bs_list)\n",
    "    if i==2:\n",
    "        n_bs_list = n_bs\n",
    "    else:\n",
    "        n_bs_list = np.vstack((n_bs_list, n_bs))\n",
    "    #n_bs_list.append(n_bs)\n",
    "#print n_bs_list.shape\n",
    "n_bs_df = pd.DataFrame(np.array(n_bs_list), columns=['RNCID', 'CellID', 'PCI',])\n",
    "n_bs_df = n_bs_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bs_df = n_bs_df.merge(eng_para, left_on=['RNCID', 'CellID'], right_on=['RNCID','CellID'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bs_df = n_bs_df[['BSID','PCI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bs_id_list=[]\n",
    "for i in range(0,n_bs_df.shape[0]):\n",
    "    #n_bs_id_list.append(n_bs_df.iloc[i,:].values)\n",
    "    n_bs_id_list.append(int(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bs_df['bs_id'] = n_bs_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "con_tr_feature, con_te_feature, con_tr_p, con_te_p = train_test_split(te_feature_r, te_label_, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_n_bs(df):\n",
    "    for i in range(2,7):\n",
    "    #con_tr_feature['BSID%d' % i] = con_tr_feature[['BSID', 'Basic_psc_pci_%d' % i]].map(lambda x: compute_n_bs_id(x)) \n",
    "        df = df.merge(n_bs_df, left_on=['BSID', 'Basic_psc_pci_%d' % i], right_on=['BSID','PCI'], how = 'left',\n",
    "                                             suffixes=('', '%d' % i))\n",
    "        \n",
    "    df.rename(columns={'bs_id':'bs_id2'}, inplace=True)\n",
    "        #print con_tr_feature.columns\n",
    "    df = df.drop(['BSID2', 'PCI',\n",
    "                 'BSID3', 'PCI3',\n",
    "                 'BSID4', 'PCI4',\n",
    "                 'BSID5', 'PCI5',\n",
    "                 'BSID6', 'PCI6',],axis=1)\n",
    "    df.rename(columns={'bs_id2':'BSID2', 'bs_id3':'BSID3','bs_id4':'BSID4',\n",
    "                                      'bs_id5':'BSID5','bs_id6':'BSID6'}, inplace=True)\n",
    "    df = df.fillna(-1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "con_tr_feature = re_n_bs(con_tr_feature)\n",
    "con_te_feature = re_n_bs(con_te_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([         u'TrajID',         u'RNCID_1',        u'CellID_1',\n",
       "            u'AsuLevel_1',           u'Dbm_1',   u'SignalLevel_1',\n",
       "               u'RNCID_2',        u'CellID_2',      u'AsuLevel_2',\n",
       "                 u'Dbm_2',   u'SignalLevel_2',         u'RNCID_3',\n",
       "              u'CellID_3',      u'AsuLevel_3',           u'Dbm_3',\n",
       "         u'SignalLevel_3',         u'RNCID_4',        u'CellID_4',\n",
       "            u'AsuLevel_4',           u'Dbm_4',   u'SignalLevel_4',\n",
       "               u'RNCID_5',        u'CellID_5',      u'AsuLevel_5',\n",
       "                 u'Dbm_5',   u'SignalLevel_5',         u'RNCID_6',\n",
       "              u'CellID_6',      u'AsuLevel_6',           u'Dbm_6',\n",
       "         u'SignalLevel_6',            u'mode', u'Basic_psc_pci_2',\n",
       "       u'Basic_psc_pci_3', u'Basic_psc_pci_4', u'Basic_psc_pci_5',\n",
       "       u'Basic_psc_pci_6',          u'MRTime',             u'Lon',\n",
       "                   u'Lat',            u'BSID',           u'BSID2',\n",
       "                 u'BSID3',           u'BSID4',           u'BSID5',\n",
       "                 u'BSID6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_tr_feature.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([         u'TrajID',         u'RNCID_1',        u'CellID_1',\n",
       "            u'AsuLevel_1',           u'Dbm_1',   u'SignalLevel_1',\n",
       "               u'RNCID_2',        u'CellID_2',      u'AsuLevel_2',\n",
       "                 u'Dbm_2',   u'SignalLevel_2',         u'RNCID_3',\n",
       "              u'CellID_3',      u'AsuLevel_3',           u'Dbm_3',\n",
       "         u'SignalLevel_3',         u'RNCID_4',        u'CellID_4',\n",
       "            u'AsuLevel_4',           u'Dbm_4',   u'SignalLevel_4',\n",
       "               u'RNCID_5',        u'CellID_5',      u'AsuLevel_5',\n",
       "                 u'Dbm_5',   u'SignalLevel_5',         u'RNCID_6',\n",
       "              u'CellID_6',      u'AsuLevel_6',           u'Dbm_6',\n",
       "         u'SignalLevel_6',            u'mode', u'Basic_psc_pci_2',\n",
       "       u'Basic_psc_pci_3', u'Basic_psc_pci_4', u'Basic_psc_pci_5',\n",
       "       u'Basic_psc_pci_6',          u'MRTime',             u'Lon',\n",
       "                   u'Lat',            u'BSID',           u'BSID2',\n",
       "                 u'BSID3',           u'BSID4',           u'BSID5',\n",
       "                 u'BSID6',            u'conf',           u'error',\n",
       "             u'Longitude',        u'Latitude',           u'p_gid',\n",
       "                   u'gid',     u'rss_level_1',     u'rss_level_2',\n",
       "           u'rss_level_3',     u'rss_level_4',     u'rss_level_5',\n",
       "           u'rss_level_6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_te_feature.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "con_tr_feature.to_csv(\"4g/conf_tr_jd4g.csv\")\n",
    "con_te_feature.to_csv(\"4g/conf_te_jd4g.csv\")\n",
    "tr_feature_r.to_csv(\"4g/total_conf_tr_jd4g.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n"
     ]
    }
   ],
   "source": [
    "import grid\n",
    "#from grid import RoadGrid\n",
    "#importlib.reload(grid)\n",
    "#from grid import RoadGrid\n",
    "rg = grid.RoadGrid(np.vstack((tr_label_.values, te_label_.values)),80)\n",
    "tr_label_g = rg.transform(tr_label_.values, False)\n",
    "#rint tr_label_\n",
    "con_tr_j = rg.transform(con_tr_p.values, False)\n",
    "con_te_j = rg.transform(con_te_p.values, False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "est=RandomForestClassifier( n_jobs=-1,\n",
    "    n_estimators =50,\n",
    "    max_features='sqrt').fit(tr_feature_r[col_name_rf].values, tr_label_g)\n",
    "    #est=DecisionTreeRegressor(max_depth=4).fit(tr_f.values, tr_l.values)\n",
    "pred_con_tr=est.predict(con_tr_feature[col_name_rf].values)\n",
    "pred_con_te=est.predict(con_te_feature[col_name_rf].values)\n",
    "tr_pred = np.array([rg.grid_center[idx] for idx in pred_con_tr])\n",
    "te_pred = np.array([rg.grid_center[idx] for idx in pred_con_te])\n",
    "error_tr = [distance(pt1, pt2) for pt1, pt2 in zip(tr_pred, con_tr_p.values)]\n",
    "#error_tr = sorted(error_tr)\n",
    "error_te = [distance(pt1, pt2) for pt1, pt2 in zip(te_pred, con_te_p.values)]\n",
    "#error_te = sorted(error_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangyige/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/zhangyige/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/zhangyige/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "tr_feature_r['Longitude'] = tr_label_.iloc[:, 0].values\n",
    "tr_feature_r['Latitude'] = tr_label_.iloc[:, 1].values\n",
    "tr_feature_r['gid'] = tr_label_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf_label_tr = conf_model_label(error_tr)\n",
    "conf_label_te = conf_model_label(error_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_tr_feature[\"conf\"]= conf_label_tr\n",
    "con_te_feature[\"conf\"]= conf_label_te\n",
    "con_tr_feature[\"error\"]= error_tr\n",
    "con_te_feature[\"error\"]= error_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_tr_feature['Longitude'] = con_tr_p.iloc[:,0].values\n",
    "con_tr_feature['Latitude'] = con_tr_p.iloc[:,1].values\n",
    "con_te_feature['Longitude'] = con_te_p.iloc[:,0].values\n",
    "con_te_feature['Latitude'] = con_te_p.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_tr_feature['p_gid'] = pred_con_tr\n",
    "con_tr_feature['gid'] = con_tr_j\n",
    "con_te_feature['p_gid'] = pred_con_te\n",
    "con_te_feature['gid'] = con_te_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rss_level(dbm):\n",
    "    if dbm>-50:\n",
    "        return 1\n",
    "    elif dbm >-60:\n",
    "        return 2\n",
    "    elif dbm >-70:\n",
    "        return 3\n",
    "    elif dbm>-80:\n",
    "        return 4\n",
    "    elif dbm>-90:\n",
    "        return 5\n",
    "    elif dbm>-100:\n",
    "        return 6\n",
    "    elif dbm>-110:\n",
    "        return 7\n",
    "    else:\n",
    "        return 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 7):\n",
    "    con_tr_feature['rss_level_%d' % i] = con_tr_feature['Dbm_%d' % i].map(lambda x: rss_level(x))  \n",
    "    con_te_feature['rss_level_%d' % i] = con_te_feature['Dbm_%d' % i].map(lambda x: rss_level(x))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ob = con_tr_feature[['BSID','rss_level_1','BSID2','rss_level_2',\n",
    "               'BSID3','rss_level_3','BSID4','rss_level_4',\n",
    "               'BSID5','rss_level_5','BSID6','rss_level_6',]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_ob_bs = con_tr_feature[['BSID','BSID2','BSID3','BSID4','BSID5','BSID6',]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ob_rss = con_tr_feature[['rss_level_1','rss_level_2','rss_level_3',\n",
    "                               'rss_level_4','rss_level_5','rss_level_6',]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ob_te = con_te_feature[['BSID','rss_level_1','BSID2','rss_level_2',\n",
    "               'BSID3','rss_level_3','BSID4','rss_level_4',\n",
    "               'BSID5','rss_level_5','BSID6','rss_level_6',]].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jaccard_sim(list1, list2):\n",
    "    list_1 = list1[1:]\n",
    "    list_2 = list2[2:]\n",
    "    #print list1, list2\n",
    "    if list1[0] == list2[0]:\n",
    "        union_set = len(set(list_1)|set(list_2))+1#并集长度\n",
    "        intersection_set = len(set(list1)&set(list2))+1#交集长度\n",
    "    else:\n",
    "        union_set = len(set(list_1)|set(list_2))#并集长度\n",
    "        intersection_set = len(set(list1)&set(list2))+2#交集长度\n",
    "\n",
    "    Jaccard = float(intersection_set/union_set) #Jaccar\n",
    "    return Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adaptive_emission_pro(jd_list, match, bs_list, ss_list, can_list, total_c, conf):\n",
    "    pro_list = []\n",
    "    weight_list = []\n",
    "    if match.shape[0]>0:\n",
    "        weight_list.append(math.log(1+match.shape[0])*1)\n",
    "        match_ss= match[(match['rss_level_1']== int(ss_list[0])) & (match['rss_level_2']==int(ss_list[1])) & (match['rss_level_3']==ss_list[2])\n",
    "             & (match['rss_level_4']==ss_list[3]) & (match['rss_level_5']==ss_list[4]) & (match['rss_level_6']==ss_list[5])]\n",
    "        if match_ss.shape[0]>0:\n",
    "            pro_list.append(float(match_ss[match_ss['conf']==conf].shape[0])/float(total_c))\n",
    "        else:\n",
    "            pro_list.append(float(match[match['conf']==conf].shape[0])/float(total_c))\n",
    "        \n",
    "        \n",
    "    for can_temp, jd in zip(can_list, jd_list):\n",
    "        match_c = con_tr_feature[(con_tr_feature['BSID']==int(can_temp[0])) & (con_tr_feature['BSID2']==int(can_temp[1]))\n",
    "                      &(con_tr_feature['BSID3']==int(can_temp[2])) & (con_tr_feature['BSID4']==int(can_temp[3]))\n",
    "                      &(con_tr_feature['BSID5']==int(can_temp[4])) & (con_tr_feature['BSID6']==int(can_temp[5]))]\n",
    "        count = match_c.shape[0]\n",
    "        weight_list.append(math.log(1+count)*jd)\n",
    "        \n",
    "        match_ss_c= match_c[(match_c['rss_level_1']== ss_list[0]) & (match_c['rss_level_2']== ss_list[1]) \n",
    "                            & (match_c['rss_level_3']==ss_list[2])& (match_c['rss_level_4']==ss_list[3]) \n",
    "                            & (match_c['rss_level_5']==ss_list[4]) & (match_c['rss_level_6']==ss_list[5])]\n",
    "        if match_ss_c.shape[0]>0:\n",
    "            pro_list.append(float(match_ss_c[match_ss_c['conf']==conf].shape[0])/float(total_c))\n",
    "        else:\n",
    "            pro_list.append(float(match_c[match_c['conf']==conf].shape[0])/float(total_c))\n",
    "\n",
    "\n",
    "    weight_sum = np.sum(weight_list)\n",
    "    ad_em_po = 0\n",
    "    \n",
    "    for x, y in zip(pro_list, weight_list):\n",
    "        ad_em_po += x * (y / weight_sum)\n",
    "    \n",
    "    return ad_em_po"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros_list = []\n",
    "i =0\n",
    "j=0\n",
    "zero_num = con_tr_feature[con_tr_feature['conf']==0].shape[0]\n",
    "for idx, row in total_ob_te.iterrows():\n",
    "    bs_list =row[['BSID','BSID2','BSID3','BSID4','BSID5','BSID6']].values\n",
    "    ss_list = row[['rss_level_1','rss_level_2','rss_level_3','rss_level_4','rss_level_5','rss_level_6',]].values\n",
    "    #print bs_list[0]\n",
    "    match = con_tr_feature[(con_tr_feature['BSID']==int(bs_list[0])) & (con_tr_feature['BSID2']==int(bs_list[1]))\n",
    "                          &(con_tr_feature['BSID3']==int(bs_list[2])) & (con_tr_feature['BSID4']==int(bs_list[3]))\n",
    "                          &(con_tr_feature['BSID5']==int(bs_list[4])) & (con_tr_feature['BSID6']==int(bs_list[5]))]\n",
    "    if match.shape[0]<5:\n",
    "        can_bs_row = []\n",
    "        can_j = []\n",
    "        jaccd_max = []\n",
    "        idx_list = []\n",
    "        for idxx, roww in total_ob_bs.iterrows():\n",
    "            can_bs_list = roww.values\n",
    "            jd = jaccard_sim(bs_list, can_bs_list)\n",
    "            jaccd_max.append(jd)\n",
    "            idx_list.append(idxx)\n",
    "            if jd>0.5:\n",
    "                can_bs_row.append(can_bs_list)\n",
    "                can_j.append(jd)\n",
    "                \n",
    "        if len(can_bs_row)==0:\n",
    "            can_idx = jaccd_max.index(np.max(jaccd_max))\n",
    "            can_temp = total_ob_bs.iloc[can_idx,:].values\n",
    "            can_bs_row.append(total_ob_bs.iloc[can_idx,:].values)\n",
    "            match_c = con_tr_feature[(con_tr_feature['BSID']==int(can_temp[0])) & (con_tr_feature['BSID2']==int(can_temp[1]))\n",
    "                          &(con_tr_feature['BSID3']==int(can_temp[2])) & (con_tr_feature['BSID4']==int(can_temp[3]))\n",
    "                          &(con_tr_feature['BSID5']==int(can_temp[4])) & (con_tr_feature['BSID6']==int(can_temp[5]))]\n",
    "            \n",
    "            match_ss_c= match_c[(match_c['rss_level_1']== ss_list[0]) & (match_c['rss_level_2']== ss_list[1]) \n",
    "                            & (match_c['rss_level_3']==ss_list[2])& (match_c['rss_level_4']==ss_list[3]) \n",
    "                            & (match_c['rss_level_5']==ss_list[4]) & (match_c['rss_level_6']==ss_list[5])]\n",
    "            if match_ss_c.shape[0]>0:\n",
    "                zeros_list.append(float(match_ss_c[match_ss_c['conf']==0].shape[0])/float(zero_num))\n",
    "            else:\n",
    "                zeros_list.append(float(match_c[match_c['conf']==0].shape[0])/float(zero_num))\n",
    "        \n",
    "            j+=1 \n",
    "        else:\n",
    "            zeros_list.append(adaptive_emission_pro(can_j, match, bs_list, ss_list, can_bs_row, zero_num, 0))\n",
    "        #print i, len(can_bs_row)\n",
    "        i+=1\n",
    "    else:\n",
    "        j+=1\n",
    "        match_ss= match[(match['rss_level_1']== int(ss_list[0])) & (match['rss_level_2']==int(ss_list[1])) & (match['rss_level_3']==ss_list[2])\n",
    "             & (match['rss_level_4']==ss_list[3]) & (match['rss_level_5']==ss_list[4]) & (match['rss_level_6']==ss_list[5])]\n",
    "        if match_ss.shape[0]>0:\n",
    "            zeros_list.append(float(match_ss[match_ss['conf']==0].shape[0])/float(zero_num))\n",
    "        else:\n",
    "            zeros_list.append(float(match[match['conf']==0].shape[0])/float(zero_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_ob_te['conf_ad_em_pro_0'] = zeros_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_list = []\n",
    "one_num = con_tr_feature[con_tr_feature['conf']==1].shape[0]\n",
    "for idx, row in total_ob_te.iterrows():\n",
    "    bs_list =row[['BSID','BSID2','BSID3','BSID4','BSID5','BSID6']].values\n",
    "    ss_list = row[['rss_level_1','rss_level_2','rss_level_3','rss_level_4','rss_level_5','rss_level_6',]].values\n",
    "    #print bs_list[0]\n",
    "    match = con_tr_feature[(con_tr_feature['BSID']==int(bs_list[0])) & (con_tr_feature['BSID2']==int(bs_list[1]))\n",
    "                          &(con_tr_feature['BSID3']==int(bs_list[2])) & (con_tr_feature['BSID4']==int(bs_list[3]))\n",
    "                          &(con_tr_feature['BSID5']==int(bs_list[4])) & (con_tr_feature['BSID6']==int(bs_list[5]))]\n",
    "    if match.shape[0]<5:\n",
    "        can_bs_row = []\n",
    "        can_j = []\n",
    "        jaccd_max = []\n",
    "        idx_list = []\n",
    "        for idxx, roww in total_ob_bs.iterrows():\n",
    "            can_bs_list = roww.values\n",
    "            jd = jaccard_sim(bs_list, can_bs_list)\n",
    "            jaccd_max.append(jd)\n",
    "            idx_list.append(idxx)\n",
    "            if jd>0.5:\n",
    "                can_bs_row.append(can_bs_list)\n",
    "                can_j.append(jd)\n",
    "                \n",
    "        if len(can_bs_row)==0:\n",
    "            can_idx = jaccd_max.index(np.max(jaccd_max))\n",
    "            can_temp = total_ob_bs.iloc[can_idx,:].values\n",
    "            can_bs_row.append(total_ob_bs.iloc[can_idx,:].values)\n",
    "            match_c = con_tr_feature[(con_tr_feature['BSID']==int(can_temp[0])) & (con_tr_feature['BSID2']==int(can_temp[1]))\n",
    "                          &(con_tr_feature['BSID3']==int(can_temp[2])) & (con_tr_feature['BSID4']==int(can_temp[3]))\n",
    "                          &(con_tr_feature['BSID5']==int(can_temp[4])) & (con_tr_feature['BSID6']==int(can_temp[5]))]\n",
    "            \n",
    "            match_ss_c= match_c[(match_c['rss_level_1']== ss_list[0]) & (match_c['rss_level_2']== ss_list[1]) \n",
    "                            & (match_c['rss_level_3']==ss_list[2])& (match_c['rss_level_4']==ss_list[3]) \n",
    "                            & (match_c['rss_level_5']==ss_list[4]) & (match_c['rss_level_6']==ss_list[5])]\n",
    "            if match_ss_c.shape[0]>0:\n",
    "                one_list.append(float(match_ss_c[match_ss_c['conf']==1].shape[0])/float(one_num))\n",
    "            else:\n",
    "                one_list.append(float(match_c[match_c['conf']==1].shape[0])/float(one_num))\n",
    "        \n",
    "        else:\n",
    "            one_list.append(adaptive_emission_pro(can_j, match, bs_list, ss_list, can_bs_row, one_num, 1))\n",
    "        \n",
    "    else:\n",
    "       \n",
    "        match_ss= match[(match['rss_level_1']== int(ss_list[0])) & (match['rss_level_2']==int(ss_list[1])) & (match['rss_level_3']==ss_list[2])\n",
    "             & (match['rss_level_4']==ss_list[3]) & (match['rss_level_5']==ss_list[4]) & (match['rss_level_6']==ss_list[5])]\n",
    "        if match_ss.shape[0]>0:\n",
    "            one_list.append(float(match_ss[match_ss['conf']==1].shape[0])/float(one_num))\n",
    "        else:\n",
    "            one_list.append(float(match[match['conf']==1].shape[0])/float(one_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_ob_te['conf_ad_em_pro_1'] = one_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_te_feature['gid'] = con_te_j\n",
    "con_te_feature['p_gid'] = pred_con_te\n",
    "con_tr_feature['gid'] = con_tr_j\n",
    "con_tr_feature['p_gid'] = pred_con_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trajs_tr = con_tr_feature.groupby(['TrajID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_list = []\n",
    "st_mat = np.zeros((14,2,2)) #0-0 0-1 1-0, 1-1\n",
    "for trajid, traj in trajs_tr:\n",
    "    traj = traj.sort_values(by=['MRTime'],ascending=True)\n",
    "    t_time = traj['MRTime'].values\n",
    "    conf = traj['conf'].values\n",
    "    for i in range(traj.shape[0]-1):\n",
    "        time_list.append(compute_time_interval(t_time[i], t_time[i + 1]))\n",
    "        idx = int(compute_time_interval(t_time[i], t_time[i + 1])/5)\n",
    "        if idx >12:\n",
    "            idx = 13\n",
    "        if conf[i]==0 and conf[i+1]==0:\n",
    "            st_mat[idx, 0, 0] +=1\n",
    "        if conf[i] ==0 and conf[i+1] ==1:\n",
    "            st_mat[idx, 0, 1] +=1\n",
    "        if conf[i]==1 and conf[i+1]==0:\n",
    "            st_mat[idx, 1, 0] +=1\n",
    "        if conf[i] ==1 and conf[i+1] ==1:\n",
    "            st_mat[idx, 1, 1] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trajs_te = con_te_feature.groupby(['TrajID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_list_t_idx = []\n",
    "#st_mat = np.zeros((14,2,2)) #0-0 0-1 1-0, 1-1\n",
    "pred_list = []\n",
    "p_g_list = []\n",
    "t_g_list = []\n",
    "for trajid, traj in trajs_te:\n",
    "    traj = traj.sort_values(by=['MRTime'],ascending=True)\n",
    "    t_time = traj['MRTime'].values\n",
    "    conf = traj['conf'].values\n",
    "    idx_list = []\n",
    "    for i in range(traj.shape[0]-1):\n",
    "        time_list.append(compute_time_interval(t_time[i], t_time[i + 1]))\n",
    "        idx = int(compute_time_interval(t_time[i], t_time[i + 1])/5)\n",
    "        if idx >12:\n",
    "            idx = 13\n",
    "        idx_list.append(idx)\n",
    "    pred_list.append(traj[['BSID','rss_level_1','BSID2','rss_level_2',\n",
    "               'BSID3','rss_level_3','BSID4','rss_level_4',\n",
    "               'BSID5','rss_level_5','BSID6','rss_level_6',]].values)\n",
    "        \n",
    "    pred_list_t_idx.append(idx_list)\n",
    "    p_g_list.append(traj['p_gid'].values)\n",
    "    t_g_list.append(traj[['Longitude','Latitude']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_prob = [float(con_tr_feature[con_tr_feature['conf']==0].shape[0])/con_tr_feature.shape[0],\n",
    "             float(con_tr_feature[con_tr_feature['conf']==1].shape[0])/con_tr_feature.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hmm_viterbi(st_mat, init_prob, emit_prob, obs_seq, t_list):\n",
    "    Nstate = 2\n",
    "    Nobs = int(emit_prob.shape[0])\n",
    "    T = len(obs_seq)\n",
    "    \n",
    "    partial_prob = np.zeros((Nstate,T))\n",
    "\n",
    "    path = np.zeros((Nstate,T))\n",
    "\n",
    "    for i in range(Nstate):\n",
    "        partial_prob[i,0] = init_prob[i] * emit_prob[obs_seq[0], i]\n",
    "        path[i,0] = i\n",
    "\n",
    "\n",
    "    for t in range(1,T,1):\n",
    "        newpath = np.zeros((Nstate,T))\n",
    "        for i in range(Nstate):\n",
    "            prob = -1.0\n",
    "            for j in range(Nstate):\n",
    "                nprob = partial_prob[j,t-1] * st_mat[t_list[t-1], j, i] * emit_prob[obs_seq[t], i]\n",
    "                if nprob > prob:\n",
    "                    prob = nprob\n",
    "                    partial_prob[i,t] = nprob\n",
    "                    newpath[i,0:t] = path[j,0:t]\n",
    "                    newpath[i,t] = i\n",
    "        path = newpath\n",
    "    \n",
    "    prob = -1.0\n",
    "    j = 0\n",
    "    for i in range(Nstate):\n",
    "        if(partial_prob[i,T-1] > prob):\n",
    "            prob = partial_prob[i,T-1]\n",
    "            j = i\n",
    "\n",
    "    return path[j,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "em_pro = total_ob_te\n",
    "em_pro = em_pro.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emit_prob = em_pro[['conf_ad_em_pro_0', 'conf_ad_em_pro_1']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.00026824],\n",
       "       [0.        , 0.00026824],\n",
       "       [0.        , 0.00026824],\n",
       "       ...,\n",
       "       [0.        , 0.00026824],\n",
       "       [0.00012724, 0.00033948],\n",
       "       [0.        , 0.00026824]])"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emit_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_g = rg.n_grid\n",
    "w = np.zeros((num_g, num_g))\n",
    "\n",
    "test = zip(pred_con_tr, con_tr_j, error_tr)\n",
    "tj_r = {}\n",
    "for ss in test:\n",
    "    #print ss\n",
    "    #w[ss[0]][num_g]=w[ss[0]][num_g]+1\n",
    "    #w[ss[0]][ss[1]]=w[ss[0]][ss[1]]+1\n",
    "    if ss[0]!=ss[1] and ss[2]>50:\n",
    "         w[ss[0]][ss[1]] +=1\n",
    "        #w[ss[0], ss[1]] += 1\n",
    "    if not tj_r.has_key(ss[0]):\n",
    "        tj_r[ss[0]]=set()\n",
    "    tj_r[ss[0]].add((ss[1]))\n",
    "\n",
    "standard_point=[]\n",
    "\n",
    "\n",
    "for item in tj_r:\n",
    "    if (len(tj_r[item])==1) and (item in tj_r[item]):\n",
    "        standard_point.append(item)\n",
    "\n",
    "for idx in range(num_g):\n",
    "    if not tj_r.has_key(idx):\n",
    "        tj_r[idx]=set()\n",
    "        tj_r[idx].add((idx))\n",
    "\n",
    "g_list=rg.gridlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_obs = {}\n",
    "for idx, row in con_tr_feature.iterrows():\n",
    "    obs = row[['BSID','rss_level_1','BSID2','rss_level_2',\n",
    "               'BSID3','rss_level_3','BSID4','rss_level_4',\n",
    "               'BSID5','rss_level_5','BSID6','rss_level_6',]].values\n",
    "    gid = int(row['gid'])\n",
    "    match = em_pro[(em_pro['BSID']==obs[0]) & (em_pro['rss_level_1']==obs[1]) & \n",
    "                      (em_pro['BSID2']==obs[2]) & (em_pro['rss_level_2']==obs[3]) & \n",
    "                      (em_pro['BSID3']==obs[4]) & (em_pro['rss_level_3']==obs[5]) & \n",
    "                      (em_pro['BSID4']==obs[6]) & (em_pro['rss_level_4']==obs[7]) & \n",
    "                      (em_pro['BSID5']==obs[8]) & (em_pro['rss_level_5']==obs[9]) & \n",
    "                      (em_pro['BSID6']==obs[10]) & (em_pro['rss_level_6']==obs[11])]\n",
    "    if match.shape[0]>0:\n",
    "        obs_idx = (gid, int(match.index[0]))\n",
    "        if not g_obs.has_key(obs_idx):\n",
    "            g_obs[obs_idx]=1\n",
    "        else:\n",
    "            g_obs[obs_idx] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repair(te_pred, cof_list, o_list):\n",
    "    i=0\n",
    "    te_pred_n=[]\n",
    "    while i < len(cof_list):\n",
    "        if cof_list[i]==0:\n",
    "            pred_temp = te_pred[i]\n",
    "            if pred_temp in standard_point:\n",
    "                te_pred_n.append(te_pred[i])\n",
    "            else:\n",
    "                repair_r = list(w[te_pred[i], :])\n",
    "                max_idx = repair_r.index(np.max(repair_r))\n",
    "                if g_obs.has_key((max_idx, o_list[i])):\n",
    "                    te_pred_n.append(int(max_idx))\n",
    "                    #print 'ok'\n",
    "                else:\n",
    "                    \n",
    "                    te_pred_n.append(te_pred[i])\n",
    "                \n",
    "        else:\n",
    "            repair_r = list(w[te_pred[i], :])\n",
    "            max_idx = repair_r.index(np.max(repair_r))\n",
    "            if g_obs.has_key((max_idx, o_list[i])) and g_obs.has_key((te_pred[i], o_list[i])):\n",
    "                if g_obs[(max_idx, o_list[i])] > g_obs[(te_pred[i], o_list[i])]:\n",
    "                    te_pred_n.append(max_idx)\n",
    "                    #print 'okk'\n",
    "                else:\n",
    "                    te_pred_n.append(te_pred[i])\n",
    "            elif g_obs.has_key((max_idx, o_list[i])) and not g_obs.has_key((te_pred[i], o_list[i])):\n",
    "                te_pred_n.append(max_idx)\n",
    "                #print 'okkk'\n",
    "            else:\n",
    "                te_pred_n.append(te_pred[i])\n",
    "            \n",
    "        i+=1\n",
    "            \n",
    "    print len(te_pred_n)\n",
    "    return te_pred_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n",
      "4\n",
      "okkk\n",
      "11\n",
      "1\n",
      "2\n",
      "okk\n",
      "29\n",
      "ok\n",
      "okkk\n",
      "ok\n",
      "okkk\n",
      "171\n",
      "okk\n",
      "ok\n",
      "okkk\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "okkk\n",
      "okk\n",
      "ok\n",
      "okkk\n",
      "okkk\n",
      "ok\n",
      "okkk\n",
      "ok\n",
      "okkk\n",
      "153\n",
      "okkk\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "okkk\n",
      "okkk\n",
      "ok\n",
      "102\n",
      "okkk\n",
      "ok\n",
      "okkk\n",
      "okk\n",
      "46\n",
      "29\n",
      "33\n",
      "okkk\n",
      "okk\n",
      "16\n",
      "27\n",
      "okkk\n",
      "okkk\n",
      "okkk\n",
      "okkk\n",
      "60\n",
      "ok\n",
      "okkk\n",
      "okk\n",
      "okkk\n",
      "175\n",
      "ok\n",
      "ok\n",
      "32\n",
      "okkk\n",
      "okk\n",
      "okkk\n",
      "okkk\n",
      "okkk\n",
      "okkk\n",
      "okk\n",
      "288\n",
      "okkk\n",
      "32\n",
      "okkk\n",
      "okkk\n",
      "okkk\n",
      "28\n",
      "ok\n",
      "okk\n",
      "okk\n",
      "52\n",
      "47\n",
      "ok\n",
      "okkk\n",
      "42\n",
      "38\n",
      "okkk\n",
      "29\n",
      "okk\n",
      "okkk\n",
      "okkk\n",
      "39\n",
      "31\n",
      "okkk\n",
      "32\n",
      "28\n",
      "45\n",
      "okkk\n",
      "35\n",
      "okk\n",
      "okk\n",
      "okk\n",
      "okk\n",
      "26\n",
      "okk\n",
      "ok\n",
      "ok\n",
      "okkk\n",
      "okkk\n",
      "okkk\n",
      "okkk\n",
      "okkk\n",
      "49\n",
      "okkk\n",
      "okkk\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "42\n",
      "26\n",
      "okkk\n",
      "okkk\n",
      "885\n",
      "okkk\n",
      "okkk\n",
      "ok\n",
      "ok\n",
      "okkk\n",
      "74\n",
      "okkk\n",
      "ok\n",
      "34\n",
      "23\n",
      "okkk\n",
      "32\n",
      "41\n",
      "okkk\n",
      "okkk\n",
      "okk\n",
      "48\n",
      "okk\n",
      "115\n",
      "42\n",
      "7\n",
      "ok\n",
      "okkk\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "error_list = []\n",
    "error_new = []\n",
    "i=0\n",
    "for row, time, raw, gt in zip (pred_list, pred_list_t_idx, p_g_list, t_g_list):\n",
    "    o_seq = []\n",
    "    for obs in row:\n",
    "        #print obs\n",
    "        match = em_pro[(em_pro['BSID']==obs[0]) & (em_pro['rss_level_1']==obs[1]) & \n",
    "                      (em_pro['BSID2']==obs[2]) & (em_pro['rss_level_2']==obs[3]) & \n",
    "                      (em_pro['BSID3']==obs[4]) & (em_pro['rss_level_3']==obs[5]) & \n",
    "                      (em_pro['BSID4']==obs[6]) & (em_pro['rss_level_4']==obs[7]) & \n",
    "                      (em_pro['BSID5']==obs[8]) & (em_pro['rss_level_5']==obs[9]) & \n",
    "                      (em_pro['BSID6']==obs[10]) & (em_pro['rss_level_6']==obs[11])]\n",
    "        o_seq.append(match.index[0])\n",
    "    pred = raw\n",
    "    true = gt\n",
    "    cof_list = hmm_viterbi(st_mat, init_prob, emit_prob, o_seq, time)\n",
    "    \n",
    "    r_pred = repair(pred, cof_list, o_seq)\n",
    "    #print r_pred\n",
    "    \n",
    "   \n",
    "    te_predp = np.array([rg.grid_center[idx] for idx in r_pred])\n",
    "    #print true\n",
    "    \n",
    "    #tps = np.array([rg.grid_center[idx] for idx in true])\n",
    "   \n",
    "    error_tep = [distance(pt1, pt2) for pt1, pt2 in zip(te_predp, true)]\n",
    "    #print np.mean(error_trp), np.mean(error_tep)\n",
    "   \n",
    "    for t in error_tep:\n",
    "        #print t\n",
    "        error_new.append(t)\n",
    "    i+=1\n",
    "    #print pred\n",
    "    #print 'a', r_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3127"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(error_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "err= sorted(error_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.4 55.11471058522546 128.5\n"
     ]
    }
   ],
   "source": [
    "print np.median(error_new), np.mean(error_new), err[int(len(err) * 0.90)]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "py27",
   "language": "python",
   "name": "py27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
